In recent years, deep learning has been applied in vari- ous elds and used to solve many challenging AI tasks, in areas such as image classi cation [ 1,2], object detection [ 3], and language modeling [ 4,5]. Speci cally, since AlexNet [ 1] outperformed all other traditional manual methods in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [ 6], increasingly complex and deep neural net- works have been proposed. For example, VGG-16 [ 7] has more than 130 million parameters, occupies nearly 500 MB of memory space, and requires 15.3 billion oating-point operations to process an image of size 224 224. Notably, however, these models were all manually designed by ex- perts by a trial-and-error process, which means that even experts require substantial resources and time to create well-performing models. To reduce these onerous development costs, a novel idea of automating the entire pipeline of machine learning (ML) has emerged, i.e., automated machine learning (AutoML). There are various de nitions of AutoML. For example, ac- cording to [ 8], AutoML is designed to reduce the demand for data scientists and enable domain experts to automati- cally build ML applications without much requirement for statistical and ML knowledge. In [ 9], AutoML is de ned as a combination of automation and ML. In a word, AutoML Corresponding author Email addresses: csxinhe@comp.hkbu.edu.hk (Xin He), kyzhao@comp.hkbu.edu.hk (Kaiyong Zhao), chxw@comp.hkbu.edu.hk (Xiaowen Chu)can be understood to involve the automated construction of an ML pipeline on the limited computational budget. With the exponential growth of computing power, AutoML has become a hot topic in both industry and academia. A complete AutoML system can make a dynamic combination of various techniques to form an easy-to-use end-to-end ML pipeline system (as shown in Figure 1). Many AI com- panies have created and publicly shared such systems (e.g., Cloud AutoML1by Google) to help people with little or no ML knowledge to build high-quality custom models. As Figure 1 shows, the AutoML pipeline consists of several processes: data preparation, feature engineering, model generation, and model evaluation. Model generation can be further divided into search space and optimization methods . The search space de nes the design principles of ML models, which can be divided into two categories: the traditional ML models (e.g., SVM and KNN), and neural architectures. The optimization methods are classi ed into hyperparameter optimization (HPO) and architecture optimization (AO) , where the former indicates the training- related parameters (e.g., the learning rate and batch size), and the latter indicates the model-related parameters (e.g., the number of layer for neural architectures and the number of neighbors for KNN). NAS consists of three important components: the search space of neural architectures, AO methods, and model evaluation methods. AO methods may also refer to search strategy [10] orsearch policy [11]. Zoph et al. [ 12] were one of the rst to propose NAS, where a 1https://cloud.google.com/automl/ Preprint submitted to Knowledge-Based Systems April 19, 2021arXiv:1908.00709v6 [cs.LG] 16 Apr 2021 Feature Selection Feature Extraction Feature Construction Feature Feature Engineering Model Generation T raditional Models (SVM, KNN) Search Space Optimization Methods Hyperparameter Optimization Model Estimation Data Collection Data Cleaning Data Preparation Data Augmentation Deep Neural Networks (CNN, RNN) Architecture Optimization Low-fidelity Early-stopping Surrogate Model W eight-sharing Neural Architecture Search (NAS)Figure 1: An overview of AutoML pipeline covering data preparation (Section 2), feature engineering (Section 3), model generation (Section 4) and model evaluation (Section 5). recurrent network is trained by reinforcement learning to automatically search for the best-performing architecture. Since [ 12] successfully discovered a neural network achieving comparable results to human-designed models, there has been an explosion of research interest in AutoML, with most focusing on NAS. NAS aims to search for a robust and well- performing neural architecture by selecting and combining di erent basic operations from a prede ned search space. By reviewing NAS methods, we classify the commonly used search space into entire-structured [12,13,14],cell-based [13,15,16,17,18],hierarchical [19] and morphism-based [20,21,22] search space. The commonly used AO methods contain reinforcement learning (RL) [ 12,15,23,16,13], evolution-based algorithm (EA) [ 24,25,26,27,28,29,30], and gradient descent (GD) [ 17,31,32],Surrogate Model- Based Optimization (SMBO) [ 33,34,35,36,37,38,39], and hybrid AO methods [40, 41, 42, 43, 44]. Although there are already several excellent AutoML- related surveys [ 10,45,46,9,8], to the best of our knowl- edge, our survey covers a broader range of AutoML meth- ods. As summarized in Table 1, [ 10,45,46] only focus on NAS, while [ 9,8] cover little of NAS technique. In this paper, we summarize the AutoML-related methods according to the complete AutoML pipeline (Figure 1), providing beginners with a comprehensive introduction to the eld. Notably, many sub-topics of AutoML are large enough to have their own surveys. However, our goal is not to conduct a thorough investigation of all AutoML sub-topics. Instead, we focus on the breadth of research in the eld of AutoML. Therefore, we will summarize and discuss some representative methods of each process in the pipeline. The rest of this paper is organized as follows. TheSurvey DP FE HPO NAS NAS Survey [10] - - - X A Survey on NAS [45] - - - X NAS Challenges [46] - - - X A Survey on AutoML [9] -X X † AutoML Challenges [47] X -X † AutoML Benchmark [8] XX X - Ours XX X X Table 1: Comparison between di erent AutoML surveys. The \Survey" column gives each survey a label based on their title for increasing the readability. DP, FE, HPO, NAS indicate data preparation, feature engineering, hyperparameter optimization and neural architecture search, respectively. \-", \ X", and \ †" indicate the content is 1) not mentioned; 2) mentioned detailed; 3) mentioned brie y, in the original paper, respectively. processes of data preparation, feature engineering, model generation, and model evaluation are presented in Sections 2, 3, 4, 5, respectively. In Section 6, we compare the performance of NAS algorithms on the CIFAR-10 and ImageNet dataset, and discuss several subtopics of great concern in NAS community: one/two-stage NAS, one-shot NAS, joint hyperparameter and architecture optimization, and resource-aware NAS. In Section 7, we describe several open problems in AutoML. We conclude our survey in Section 8.